import streamlit as st
import joblib
import re
import nltk
from nltk.corpus import stopwords
import pandas as pd

# -----------------------------
# Page config
# -----------------------------
st.set_page_config(page_title="D√©tecteur Spam or Ham", page_icon="üì©", layout="centered")

# -----------------------------
# Inject CSS (s√©curis√©)
# -----------------------------
def inject_css(path="style.css"):
    try:
        with open(path, "r", encoding="utf-8") as f:
            st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)
    except FileNotFoundError:
        # Optionnel: th√®me minimal si le fichier n‚Äôexiste pas
        st.markdown("""
        <style>
        body {background: #0f172a; color: #e5e7eb;}
        .stTextArea textarea {background:#111827; color:#e5e7eb; border-radius:10px;}
        .stButton button {background:#3b82f6; color:white; border-radius:8px;}
        </style>
        """, unsafe_allow_html=True)

inject_css()

# -----------------------------
# NLTK stopwords
# -----------------------------
nltk.download("stopwords", quiet=True)
stop_words = set(stopwords.words("english"))

# -----------------------------
# Charger mod√®le + vectorizer
# -----------------------------
@st.cache_resource(show_spinner=False)
def load_model():
    model = joblib.load("spam_model.pkl")
    vectorizer = joblib.load("tfidf.pkl")
    return model, vectorizer

try:
    model, vectorizer = load_model()
except Exception:
    st.error("‚ùå Les fichiers du mod√®le sont introuvables. Lance d'abord train_model.py")
    st.stop()

# -----------------------------
# Nettoyage texte
# -----------------------------
def clean_text(text: str) -> str:
    text = str(text).lower()
    text = re.sub(r"http\S+|www\S+", "", text)
    text = re.sub(r"[^a-zA-Z]", " ", text)
    tokens = [w for w in text.split() if w not in stop_words]
    return " ".join(tokens)

# -----------------------------
# Header
# -----------------------------
st.title("R√©alis√© par Ahmed | Khaled | Omar")
st.title("üì© D√©tecteur de Spam or Ham")

# -----------------------------
# UI principal
# -----------------------------
message = st.text_area("√âcris ton message ici :", placeholder="Colle ton SMS ou email...")

col1, col2 = st.columns([1,1])
analyze = col1.button("Analyser")
reset = col2.button("Effacer")

if reset:
    st.experimental_set_query_params()
    st.rerun()

if analyze:
    if not message.strip():
        st.warning("‚ö†Ô∏è Veuillez entrer un message.")
    else:
        cleaned = clean_text(message)
        vec = vectorizer.transform([cleaned])
        pred = model.predict(vec)[0]
        label = "‚úî Ham" if pred == 0 else "‚ùå SPAM"

        # Optionnel: afficher la confiance si disponible
        confiance = ""
        if hasattr(model, "predict_proba"):
            proba = model.predict_proba(vec)[0]
            score = proba[pred]
            confiance = f" ‚Äî Confiance: {score:.2%}"

        if pred == 0:
            st.success(f"R√©sultat : {label}{confiance}")
        else:
            st.error(f"R√©sultat : {label}{confiance}")

# -----------------------------
# Pr√©diction CSV
# -----------------------------
st.subheader("Pr√©diction sur un fichier CSV")
uploaded = st.file_uploader("Importer un fichier CSV ", type=["csv"])

def read_csv_safely(file) -> pd.DataFrame:
    encodings = ["utf-8", "latin1", "iso-8859-1", "cp1252"]
    for enc in encodings:
        try:
            return pd.read_csv(file, encoding=enc)
        except Exception:
            continue
    raise ValueError("‚ö†Ô∏è Impossible de lire le fichier CSV ‚Äî encodage non support√©.")

if uploaded:
    try:
        df = read_csv_safely(uploaded)

        # V√©rifier la colonne
        target_col = None
        for candidate in ["sms", "message", "text"]:
            if candidate in df.columns:
                target_col = candidate
                break

        if target_col is None:
            st.error("‚ö†Ô∏è Le CSV doit contenir une colonne 'sms' (ou 'message' / 'text').")
        else:
            df["cleaned"] = df[target_col].astype(str).apply(clean_text)
            X = vectorizer.transform(df["cleaned"])
            df["prediction"] = model.predict(X)

            # CORRECTION: mapping coh√©rent avec l'entra√Ænement (ham=0, spam=1)
            df["class"] = df["prediction"].map({0: "Ham", 1: "Spam"})

            st.success("Analyse termin√©e !")
            st.dataframe(df[[target_col, "class"]], use_container_width=True)

            csv_out = df.to_csv(index=False).encode("utf-8")
            st.download_button("T√©l√©charger R√©sultats", csv_out, "predictions.csv", "text/csv")

    except Exception as e:
        st.error(f"Erreur: {e}")
